{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6ce404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Agents import ShortestPathAgent\n",
    "from Agents.agent import Agent\n",
    "from Environment import env, QuoridorEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e40bd99",
   "metadata": {},
   "source": [
    "\n",
    "    How MCTS works:\n",
    "    1. Tree Traversal: Selecting the best child node\n",
    "    2. Expansion\n",
    "    3. Simulation (Rollout): Simulating a game from the selected node until the game ends\n",
    "    4. Backpropagation (Updating the tree): Updating the nodes with the results of the simulation\n",
    "\n",
    "    Algorithm for tree traversal and expansion:\n",
    "    1. Start at the root node\n",
    "    2a. While the current node is fully expanded and not a leaf node:\n",
    "        1. Select the best child node using the UCT formula if the current player has walls left\n",
    "            or the shortest path policy if the current player has no walls left\n",
    "    2b. If the current node is not fully expanded:\n",
    "        1. perform rollout policy\n",
    "    2c. If the current node is a leaf node and has been visited:\n",
    "        1. Expand the node by adding all possible children\n",
    "        2. Select a random child node\n",
    "        3. Perform rollout policy\n",
    "\n",
    "    Algorithm for rollout policy:\n",
    "    1. If the game is over:\n",
    "        1. Return the reward\n",
    "    2. Else:\n",
    "        1. Select a random action from the legal actions given the current state\n",
    "        2. Perform the action\n",
    "        3. overwrite the current state with the new state\n",
    "        4. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84ab65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quoridor import Quoridor\n",
    "from Environment.utils import (\n",
    "    convert_quoridor_move_to_discrete,\n",
    "    convert_observation_quoridor_game,\n",
    "    convert_discrete_to_quoridor_move,\n",
    ")\n",
    "from Policies.policy import ShortestPathPolicy\n",
    "from math import sqrt, log\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from typing import Set\n",
    "import time\n",
    "import graphviz\n",
    "\n",
    "EXPLORATION_CONSTANT = 1.414\n",
    "\n",
    "\n",
    "class MCTSAgent(Agent):\n",
    "    \"\"\"\n",
    "    An agent that uses Monte Carlo Tree Search to select actions\n",
    "    It utilizes the quoridor packacge to simulate games\n",
    "    and the ucb1 algorithm to select actions\n",
    "\n",
    "     we use the pgn of the game as state\n",
    "    \"\"\"\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, state, parent=None, action=None, terminal=False):\n",
    "            self.state = state\n",
    "            self.parent = parent\n",
    "            self.children = set()\n",
    "            self.total_reward = 0\n",
    "            self.visits = 0\n",
    "            self.action = action\n",
    "            self.is_terminal = terminal\n",
    "                    \n",
    "            \n",
    "        def __str__(self) -> str:\n",
    "            return f\"action: {self.action}, visits: {self.visits}, total_reward: {self.total_reward}\"\n",
    "\n",
    "        def __repr__(self) -> str:\n",
    "            return f\"action: {self.action}, visits: {self.visits}, total_reward: {self.total_reward}\"\n",
    "\n",
    "    def __init__(self, action_space=None, player=None, max_iterations=10000, max_time=10):\n",
    "        super().__init__(action_space, player)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_time = max_time\n",
    "        self.root = None\n",
    "\n",
    "    def act(self, observation, reward, info) -> int:\n",
    "        \"\"\"\n",
    "        Selects an action using the MCTS algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        quoridor: Quoridor = convert_observation_quoridor_game(\n",
    "            observation[\"observation\"], self.player\n",
    "        )\n",
    "        # if walls are not available, use shortest path policy, to speed up the game\n",
    "        if quoridor.current_player.walls == 0:\n",
    "            print(\"using shortest path policy\")\n",
    "            return ShortestPathPolicy().get_action(quoridor)\n",
    "        current_state = self._convert_quoridor_to_state(quoridor)\n",
    "\n",
    "        self.root = self.Node(info[\"pgn\"])\n",
    "        action = self._search(self.root)\n",
    "\n",
    "        \n",
    "        return convert_quoridor_move_to_discrete(action)\n",
    "\n",
    "    def _get_child_node(self, node, action):\n",
    "        \"\"\"\n",
    "        Returns the child node with the given action\n",
    "        \"\"\"\n",
    "        for child in node.children:\n",
    "            if child.action == action:\n",
    "                return child\n",
    "\n",
    "    def _expand(self, node: Node):\n",
    "        \"\"\"\n",
    "        Expands the node by adding all possible children\n",
    "        \"\"\"\n",
    "        quoridor = self._convert_state_to_quoridor(node.state)\n",
    "        for move in quoridor.get_legal_moves():\n",
    "            quoridor_copy = deepcopy(quoridor)\n",
    "            quoridor_copy.make_move(move)\n",
    "            node.children.add(\n",
    "                self.Node(\n",
    "                    state=self._convert_quoridor_to_state(quoridor_copy),\n",
    "                    parent=node,\n",
    "                    action=move,\n",
    "                    terminal=quoridor_copy.is_terminated\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _rollout(self, node):\n",
    "        \"\"\"\n",
    "        perform a rollout a from the given node\n",
    "        \"\"\"\n",
    "        quoridor = self._convert_state_to_quoridor(node.state)\n",
    "        while not quoridor.is_terminated:\n",
    "            move = self._rollout_policy(quoridor)\n",
    "            quoridor.make_move(move)\n",
    "\n",
    "        if quoridor.current_player.id == self.player:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def _rollout_policy(self, quoridor: Quoridor) -> str:\n",
    "        \"\"\"\n",
    "        Selects a random action from the legal actions given the current state\n",
    "        \"\"\"\n",
    "        # if quoridor.current_player.walls > 0:\n",
    "        return random.choice(list(quoridor.get_legal_pawn_moves()))\n",
    "        # else:\n",
    "        return convert_discrete_to_quoridor_move(\n",
    "            ShortestPathPolicy().get_action(quoridor)\n",
    "        )\n",
    "\n",
    "    def _backpropagate(self, node: Node, reward):\n",
    "        \"\"\"\n",
    "        Backpropagates the reward up the tree\n",
    "        \"\"\"\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.total_reward += reward\n",
    "            node = node.parent\n",
    "            reward *= -1\n",
    "\n",
    "    def _best_child(self, node):\n",
    "        \"\"\"\n",
    "        Returns the best child of the given node\n",
    "        \"\"\"\n",
    "        for child in node.children:\n",
    "            if child.visits == 0:\n",
    "                return child\n",
    "        return max(node.children, key=self._uct_score)\n",
    "\n",
    "    def _best_action(self, node: Node):\n",
    "        \"\"\"\n",
    "        Returns the best action from the given node\n",
    "        \"\"\"\n",
    "        best_node = max(node.children, key=lambda x: x.total_reward)\n",
    "        return best_node.action\n",
    "\n",
    "    def _search(self, root):\n",
    "        \"\"\"\n",
    "        Searches the tree starting from the given root node\n",
    "        \"\"\"\n",
    "        print(\"searching\")\n",
    "        start = time.time()\n",
    "\n",
    "        for i in range(self.max_iterations):\n",
    "            if i % 1000 == 0:\n",
    "                print(i)\n",
    "            \n",
    "            node = self._tree_traversal(root)\n",
    "            reward = self._rollout(node)\n",
    "            self._backpropagate(node, reward)\n",
    "            # graph = self.create_graphviz_tree(root)\n",
    "            # graph.render(\"mcts_tree\", format=\"png\", view=True)\n",
    "            # print the children of the root node sorted by total reward\n",
    "        print(sorted(root.children, key=lambda x: x.total_reward, reverse=True)[:10])\n",
    "        end = time.time()\n",
    "        print(f\"search time: {end-start}\")\n",
    "        return self._best_action(root)\n",
    "\n",
    "    def _tree_traversal(self, node):\n",
    "        \"\"\"\n",
    "        Traverses the tree starting from the given node\n",
    "        \"\"\"\n",
    "        while not node.is_terminal:\n",
    "            if len(node.children) == 0:\n",
    "                self._expand(node)\n",
    "                return random.choice(list(node.children))\n",
    "            else:\n",
    "                node = self._best_child(node)\n",
    "        return node\n",
    "\n",
    "    def _uct_score(self, node: Node):\n",
    "        \"\"\"\n",
    "        Calculates the UCT score of the given node\n",
    "        \"\"\"\n",
    "        return node.total_reward / node.visits + EXPLORATION_CONSTANT * sqrt(\n",
    "            log(node.parent.visits) / node.visits\n",
    "        )\n",
    "\n",
    "    def _convert_state_to_quoridor(self, state) -> Quoridor:\n",
    "        \"\"\"\n",
    "        Converts the given state to a Quoridor game\n",
    "        \"\"\"\n",
    "        return Quoridor.init_from_pgn(state)\n",
    "\n",
    "    def _convert_quoridor_to_state(self, quoridor: Quoridor):\n",
    "        \"\"\"\n",
    "        Converts the given Quoridor game to a state\n",
    "        \"\"\"\n",
    "        return quoridor.get_pgn()\n",
    "\n",
    "    def create_graphviz_tree(self, root_node):\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.attr(\"node\", shape=\"circle\")  # Set node shape to circle\n",
    "\n",
    "        def add_node_to_graph(node):\n",
    "            dot.node(str(id(node)), str(node))  # Add node to the graph\n",
    "\n",
    "            for child in node.children:\n",
    "                dot.edge(\n",
    "                    str(id(node)),\n",
    "                    f\"{child.action} total_reward: {child.total_reward} total_visits: {child.visits}\",\n",
    "                    label=str(child.action),\n",
    "                )  # Add edge from parent to child\n",
    "                # add_node_to_graph(child)  # Recursively add child nodes\n",
    "\n",
    "        add_node_to_graph(root_node)\n",
    "\n",
    "        return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8e59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play():\n",
    "    quoridor_env: QuoridorEnv = env()\n",
    "    agents: dict[str, Agent] = {\n",
    "        \"player_1\": ShortestPathAgent(quoridor_env.action_spaces[\"player_1\"], 1),\n",
    "        \"player_2\": MCTSAgent(quoridor_env.action_spaces[\"player_2\"], 2),\n",
    "    }\n",
    "\n",
    "    quoridor_env.reset()\n",
    "    for agent in quoridor_env.agent_iter():\n",
    "        observation, reward, termination, truncation, info = quoridor_env.last()\n",
    "        if termination:\n",
    "            if quoridor_env.rewards[\"player_1\"] == 1:\n",
    "                print(\"You won!\")\n",
    "            else:\n",
    "                print(\"You lost!\")\n",
    "            break\n",
    "        action = agents[agent].act(observation, reward, info)\n",
    "        quoridor_env.step(action)\n",
    "        \n",
    "    print(info[\"pgn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae182f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323a4882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: e8, visits: 173, total_reward: 19, action: a7h, visits: 175, total_reward: 19, action: h6h, visits: 165, total_reward: 17, action: e5v, visits: 159, total_reward: 15, action: g7h, visits: 154, total_reward: 14, action: a8h, visits: 146, total_reward: 12, action: g8v, visits: 138, total_reward: 10, action: d7h, visits: 137, total_reward: 9, action: c8v, visits: 135, total_reward: 9, action: e4h, visits: 130, total_reward: 8]\n",
      "search time: 623.2815382480621\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: h7v, visits: 229, total_reward: 29, action: c8h, visits: 184, total_reward: 18, action: g7h, visits: 178, total_reward: 16, action: f7h, visits: 173, total_reward: 15, action: d7h, visits: 154, total_reward: 10, action: e3h, visits: 151, total_reward: 9, action: d8h, visits: 149, total_reward: 9, action: d8, visits: 148, total_reward: 8, action: h7h, visits: 139, total_reward: 7, action: g2v, visits: 141, total_reward: 7]\n",
      "search time: 629.653177022934\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: e6v, visits: 433, total_reward: 79, action: f6h, visits: 283, total_reward: 37, action: c1v, visits: 205, total_reward: 17, action: g4v, visits: 190, total_reward: 14, action: e4h, visits: 192, total_reward: 14, action: f1h, visits: 180, total_reward: 12, action: b6h, visits: 182, total_reward: 12, action: e8h, visits: 148, total_reward: 4, action: e4v, visits: 131, total_reward: 1, action: g2v, visits: 133, total_reward: 1]\n",
      "search time: 1132.1863853931427\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: g7h, visits: 1688, total_reward: 278, action: d6h, visits: 963, total_reward: 115, action: g8h, visits: 377, total_reward: 13, action: d2v, visits: 15, total_reward: -13, action: b6h, visits: 18, total_reward: -14, action: c5v, visits: 18, total_reward: -14, action: d3v, visits: 20, total_reward: -14, action: g2h, visits: 20, total_reward: -14, action: a2h, visits: 20, total_reward: -14, action: c4h, visits: 20, total_reward: -14]\n",
      "search time: 1405.736831665039\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: f8h, visits: 2604, total_reward: 912, action: d6h, visits: 750, total_reward: 66, action: d3v, visits: 18, total_reward: -14, action: e4v, visits: 18, total_reward: -14, action: e2v, visits: 21, total_reward: -15, action: e2h, visits: 23, total_reward: -15, action: d8, visits: 23, total_reward: -15, action: d5h, visits: 21, total_reward: -15, action: c4v, visits: 26, total_reward: -16, action: g6h, visits: 26, total_reward: -16]\n",
      "search time: 1365.9861357212067\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: d7h, visits: 6304, total_reward: 870, action: f1h, visits: 13, total_reward: -13, action: g5h, visits: 13, total_reward: -13, action: a3v, visits: 17, total_reward: -15, action: d2h, visits: 17, total_reward: -15, action: c7v, visits: 17, total_reward: -15, action: d6h, visits: 17, total_reward: -15, action: g2h, visits: 17, total_reward: -15, action: g3v, visits: 17, total_reward: -15, action: c4h, visits: 20, total_reward: -16]\n",
      "search time: 895.3422107696533\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: d4h, visits: 2914, total_reward: 864, action: g6v, visits: 818, total_reward: 184, action: c8h, visits: 297, total_reward: 37, action: a7h, visits: 242, total_reward: 24, action: c6v, visits: 190, total_reward: 12, action: b7h, visits: 192, total_reward: 12, action: b8h, visits: 180, total_reward: 10, action: a8h, visits: 130, total_reward: 0, action: f6h, visits: 107, total_reward: -5, action: c7v, visits: 105, total_reward: -5]\n",
      "search time: 519.7636594772339\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: a8h, visits: 5732, total_reward: 1004, action: b7h, visits: 463, total_reward: 15, action: b3v, visits: 13, total_reward: -13, action: e1v, visits: 16, total_reward: -14, action: g3h, visits: 16, total_reward: -14, action: d8h, visits: 21, total_reward: -15, action: f4h, visits: 21, total_reward: -15, action: d3v, visits: 19, total_reward: -15, action: f5v, visits: 21, total_reward: -15, action: d1v, visits: 21, total_reward: -15]\n",
      "search time: 505.84321904182434\n",
      "searching\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "[action: c2v, visits: 4169, total_reward: 2243, action: f5h, visits: 23, total_reward: -19, action: a4h, visits: 23, total_reward: -19, action: a6h, visits: 23, total_reward: -19, action: b8v, visits: 26, total_reward: -20, action: b6v, visits: 26, total_reward: -20, action: f3h, visits: 26, total_reward: -20, action: a3h, visits: 26, total_reward: -20, action: f8, visits: 26, total_reward: -20, action: a7h, visits: 26, total_reward: -20]\n",
      "search time: 489.4707455635071\n",
      "You won!\n",
      "e2/e8/e3/h7v/e4/e6v/e5/g7h/e6/f8h/e7/d7h/d7/d4h/c7/a8h/c8/c2v/c9\n"
     ]
    }
   ],
   "source": [
    "play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b28fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
