{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6ce404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment import QuoridorEnv, env\n",
    "from Agents import MCTSAgent, ShortestPathAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0598c",
   "metadata": {},
   "source": [
    "# Introduction: Experimenting with the MCTS Algorithm and Iteration Performance\n",
    "This Jupyter Notebook aims to explore the Monte Carlo Tree Search (MCTS) algorithm and its performance in relation to the number of iterations used during the search process. MCTS is a popular algorithm used in decision-making processes, particularly in games or other domains with large state spaces and uncertain outcomes.\n",
    "\n",
    "The MCTS algorithm involves four key steps: Tree Traversal, Expansion, Simulation (Rollout), and Backpropagation. By iteratively traversing the search tree, expanding nodes, simulating game outcomes, and updating the tree based on the results, MCTS intelligently explores the state space and makes informed decisions.\n",
    "\n",
    "In this notebook, we will focus on the impact of the number of iterations on the algorithm's performance. By varying the number of iterations, we can examine how the algorithm's decision-making capabilities improve or stabilize over time. I also look at the increase of search time when the interactions are increaded.\n",
    "\n",
    "By the end of this notebook, I hope to gain a better understanding of how the amount of iterations influences the performance of the MCTS algorithm, allowing me to think of next steps how to improve the MCTS algorithm for quoridor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8e59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(max_iterations=10000):\n",
    "    quoridor_env: QuoridorEnv = env()\n",
    "    agents: dict[str, Agent] = {\n",
    "        \"player_1\": ShortestPathAgent(quoridor_env.action_spaces[\"player_1\"], 1),\n",
    "        \"player_2\": MCTSAgent(player=2, max_iterations=max_iterations),\n",
    "    }\n",
    "\n",
    "    quoridor_env.reset()\n",
    "    for agent in quoridor_env.agent_iter():\n",
    "        observation, reward, termination, truncation, info = quoridor_env.last()\n",
    "        if termination:\n",
    "            if quoridor_env.rewards[\"player_1\"] == 1:\n",
    "                print(\"You won!\")\n",
    "            else:\n",
    "                print(\"You lost!\")\n",
    "            break\n",
    "        action = agents[agent].act(observation, reward, info)\n",
    "        quoridor_env.step(action)\n",
    "        \n",
    "    print(info[\"pgn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc0f44",
   "metadata": {},
   "source": [
    "## Iteration steps\n",
    "\n",
    "In this notebook we will look at iterations of the following steps:\n",
    "\n",
    "- 100\n",
    "- 1000\n",
    "- 10000\n",
    "\n",
    "These iterations will allow me to see how performance will increase and will give me a good estimate how the search time grows when we increase the steps. Each experiment generates a pgn, which is a format that can be used to vizualise the game. This repo contains a vizualiser: https://github.com/Tientjie-san/quoridorWGUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323a4882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\OneDrive\\Bureaublad\\QuoridorEnvironment\\.venv\\Lib\\site-packages\\pettingzoo\\utils\\wrappers\\base.py:64: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching\n",
      "iteration 1\n",
      "[action: e5h, visits: 1, total_reward: 1, action: e5v, visits: 1, total_reward: 1, action: g7v, visits: 1, total_reward: 1, action: e6h, visits: 1, total_reward: 1, action: c1h, visits: 1, total_reward: 1, action: e6v, visits: 1, total_reward: 1, action: b8h, visits: 1, total_reward: 1, action: e7h, visits: 1, total_reward: 1, action: g7h, visits: 1, total_reward: 1, action: c4h, visits: 1, total_reward: 1]\n",
      "search time: 7.61453104019165\n",
      "searching\n",
      "iteration 1\n",
      "[action: b8h, visits: 1, total_reward: 1, action: c1h, visits: 1, total_reward: 1, action: g5v, visits: 1, total_reward: 1, action: g8h, visits: 1, total_reward: 1, action: c2v, visits: 1, total_reward: 1, action: h1h, visits: 1, total_reward: 1, action: c3v, visits: 1, total_reward: 1, action: c5h, visits: 1, total_reward: 1, action: c8h, visits: 1, total_reward: 1, action: g4v, visits: 1, total_reward: 1]\n",
      "search time: 6.606518030166626\n",
      "searching\n",
      "iteration 1\n",
      "[action: a3h, visits: 1, total_reward: 1, action: a2h, visits: 1, total_reward: 1, action: b5v, visits: 1, total_reward: 1, action: g8v, visits: 1, total_reward: 1, action: c5v, visits: 1, total_reward: 1, action: f1h, visits: 1, total_reward: 1, action: a1h, visits: 1, total_reward: 1, action: c3v, visits: 1, total_reward: 1, action: e7h, visits: 1, total_reward: 1, action: f8v, visits: 1, total_reward: 1]\n",
      "search time: 6.060941696166992\n",
      "searching\n",
      "iteration 1\n",
      "[action: a5v, visits: 1, total_reward: 1, action: b5v, visits: 1, total_reward: 1, action: f9, visits: 1, total_reward: 1, action: b1h, visits: 1, total_reward: 1, action: b3v, visits: 1, total_reward: 1, action: d9, visits: 1, total_reward: 1, action: a4h, visits: 1, total_reward: 1, action: a2h, visits: 1, total_reward: 1, action: b2h, visits: 1, total_reward: 1, action: b2v, visits: 1, total_reward: 1]\n",
      "search time: 6.009121417999268\n",
      "searching\n",
      "iteration 1\n",
      "[action: e8v, visits: 1, total_reward: 1, action: e1h, visits: 1, total_reward: 1, action: f2v, visits: 1, total_reward: 1, action: d7h, visits: 1, total_reward: 1, action: f3v, visits: 1, total_reward: 1, action: d6h, visits: 1, total_reward: 1, action: f4v, visits: 1, total_reward: 1, action: e8, visits: 1, total_reward: 1, action: d4v, visits: 1, total_reward: 1, action: e2h, visits: 1, total_reward: 1]\n",
      "search time: 5.809875965118408\n",
      "searching\n",
      "iteration 1\n",
      "[action: b4h, visits: 1, total_reward: 1, action: c7h, visits: 1, total_reward: 1, action: c6h, visits: 1, total_reward: 1, action: c5h, visits: 1, total_reward: 1, action: c3v, visits: 1, total_reward: 1, action: e8, visits: 1, total_reward: 1, action: g2v, visits: 1, total_reward: 1, action: g1v, visits: 1, total_reward: 1, action: f8v, visits: 1, total_reward: 1, action: f5v, visits: 1, total_reward: 1]\n",
      "search time: 5.425695896148682\n",
      "searching\n",
      "iteration 1\n",
      "[action: h2h, visits: 1, total_reward: 1, action: h1h, visits: 1, total_reward: 1, action: d4h, visits: 1, total_reward: 1, action: g8h, visits: 1, total_reward: 1, action: d9, visits: 1, total_reward: 1, action: g7h, visits: 1, total_reward: 1, action: g6h, visits: 1, total_reward: 1, action: d3h, visits: 1, total_reward: 1, action: g5h, visits: 1, total_reward: 1, action: d5v, visits: 1, total_reward: 1]\n",
      "search time: 5.446899652481079\n",
      "searching\n",
      "iteration 1\n",
      "[action: c6v, visits: 1, total_reward: 1, action: a2v, visits: 1, total_reward: 1, action: b2v, visits: 1, total_reward: 1, action: a7v, visits: 1, total_reward: 1, action: h8h, visits: 1, total_reward: 1, action: c5v, visits: 1, total_reward: 1, action: h7h, visits: 1, total_reward: 1, action: h6h, visits: 1, total_reward: 1, action: b3v, visits: 1, total_reward: 1, action: b5v, visits: 1, total_reward: 1]\n",
      "search time: 5.4687254428863525\n",
      "You won!\n",
      "e2/e5h/d2/b8h/d3/a3h/d4/a5v/d5/e8v/d6/b4h/d7/h2h/d8/c6v/d9\n"
     ]
    }
   ],
   "source": [
    "play(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e6312",
   "metadata": {},
   "source": [
    "Te zien is dat een iteratie van 100 voor MCTS op Quoridor waardeloos is. Dit komt door de hoge branching factor van quoridor. Aan het begin van een game heb je al meer dan 100 legale zeten. Dus wanneer de iteratie 100 is, dan gaat ie langs de 1e 100 random states. Die states worden maar 1 keer bezocht dus, het algoritme kan op dit moment nog niet inschatten wat een goede zet zou zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea2f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching\n",
      "iteration 1\n",
      "[action: b5v, visits: 21, total_reward: 9, action: e6h, visits: 20, total_reward: 8, action: c1v, visits: 18, total_reward: 6, action: a2v, visits: 17, total_reward: 5, action: a7v, visits: 17, total_reward: 5, action: d9, visits: 17, total_reward: 5, action: f5h, visits: 15, total_reward: 5, action: a4h, visits: 16, total_reward: 4, action: h3h, visits: 13, total_reward: 3, action: a5v, visits: 13, total_reward: 3]\n",
      "search time: 65.87558436393738\n",
      "searching\n",
      "iteration 1\n",
      "[action: g7h, visits: 22, total_reward: 10, action: e6h, visits: 21, total_reward: 9, action: h1h, visits: 20, total_reward: 8, action: d7h, visits: 20, total_reward: 8, action: b1v, visits: 15, total_reward: 5, action: f8v, visits: 15, total_reward: 5, action: g5h, visits: 15, total_reward: 5, action: b3v, visits: 14, total_reward: 4, action: b7h, visits: 14, total_reward: 4, action: c2v, visits: 14, total_reward: 4]\n",
      "search time: 65.12776160240173\n",
      "searching\n",
      "iteration 1\n",
      "[action: c7h, visits: 21, total_reward: 7, action: f8v, visits: 21, total_reward: 7, action: c2v, visits: 18, total_reward: 6, action: h5v, visits: 17, total_reward: 5, action: a7v, visits: 16, total_reward: 4, action: d1v, visits: 16, total_reward: 4, action: h4h, visits: 16, total_reward: 4, action: d4h, visits: 15, total_reward: 3, action: g1v, visits: 15, total_reward: 3, action: h7v, visits: 15, total_reward: 3]\n",
      "search time: 59.63559031486511\n",
      "searching\n",
      "iteration 1\n",
      "[action: d8v, visits: 29, total_reward: 15, action: c2h, visits: 19, total_reward: 7, action: e5v, visits: 17, total_reward: 5, action: e8v, visits: 17, total_reward: 5, action: c3v, visits: 17, total_reward: 5, action: c6h, visits: 16, total_reward: 4, action: f2h, visits: 16, total_reward: 4, action: e5h, visits: 16, total_reward: 4, action: d2h, visits: 16, total_reward: 4, action: d4h, visits: 16, total_reward: 4]\n",
      "search time: 58.01826786994934\n",
      "searching\n",
      "iteration 1\n",
      "[action: a4v, visits: 20, total_reward: 4, action: e6h, visits: 19, total_reward: 3, action: f5v, visits: 16, total_reward: 2, action: c5v, visits: 16, total_reward: 2, action: a6h, visits: 16, total_reward: 2, action: c6v, visits: 15, total_reward: 1, action: g1v, visits: 15, total_reward: 1, action: b1h, visits: 15, total_reward: 1, action: h4h, visits: 15, total_reward: 1, action: b2h, visits: 12, total_reward: 0]\n",
      "search time: 55.88866472244263\n",
      "searching\n",
      "iteration 1\n",
      "[action: h7v, visits: 20, total_reward: 2, action: b7v, visits: 17, total_reward: 1, action: f8v, visits: 17, total_reward: 1, action: h1v, visits: 19, total_reward: 1, action: f3v, visits: 17, total_reward: 1, action: c5h, visits: 19, total_reward: 1, action: b1v, visits: 16, total_reward: 0, action: a8h, visits: 16, total_reward: 0, action: f6v, visits: 16, total_reward: 0, action: e7h, visits: 15, total_reward: -1]\n",
      "search time: 53.468565464019775\n",
      "searching\n",
      "iteration 1\n",
      "[action: a6v, visits: 23, total_reward: -3, action: e8h, visits: 21, total_reward: -3, action: d2v, visits: 16, total_reward: -4, action: h4h, visits: 11, total_reward: -5, action: h1h, visits: 9, total_reward: -5, action: g8h, visits: 5, total_reward: -5, action: a5h, visits: 9, total_reward: -5, action: g6h, visits: 11, total_reward: -5, action: g5h, visits: 9, total_reward: -5, action: h1v, visits: 11, total_reward: -5]\n",
      "search time: 49.0275514125824\n",
      "You won!\n",
      "e2/b5v/e3/g7h/e4/c7h/e5/d8v/e6/a4v/e7/h7v/e8/a6v/f9\n"
     ]
    }
   ],
   "source": [
    "play(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fabed3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ddf4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: a5h, visits: 301, total_reward: 55, action: f3v, visits: 199, total_reward: 25, action: f5h, visits: 174, total_reward: 18, action: d6v, visits: 165, total_reward: 15, action: h6h, visits: 165, total_reward: 15, action: b8v, visits: 158, total_reward: 14, action: g8h, visits: 155, total_reward: 13, action: h8h, visits: 154, total_reward: 12, action: h7v, visits: 147, total_reward: 11, action: c8h, visits: 147, total_reward: 11]\n",
      "search time: 636.5566816329956\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: e6v, visits: 265, total_reward: 51, action: f7h, visits: 217, total_reward: 35, action: g7h, visits: 211, total_reward: 33, action: h5h, visits: 200, total_reward: 30, action: h7h, visits: 200, total_reward: 30, action: f5v, visits: 171, total_reward: 21, action: c8v, visits: 164, total_reward: 20, action: a1h, visits: 164, total_reward: 20, action: a3v, visits: 158, total_reward: 18, action: a8h, visits: 152, total_reward: 16]\n",
      "search time: 630.6184105873108\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: c2v, visits: 893, total_reward: 149, action: g6h, visits: 259, total_reward: 11, action: d5h, visits: 259, total_reward: 11, action: f2v, visits: 235, total_reward: 7, action: f7v, visits: 222, total_reward: 4, action: g7h, visits: 166, total_reward: -4, action: d8v, visits: 157, total_reward: -5, action: h6h, visits: 165, total_reward: -5, action: g8h, visits: 152, total_reward: -6, action: d9, visits: 129, total_reward: -9]\n",
      "search time: 593.9415242671967\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: d6h, visits: 2186, total_reward: 424, action: d2v, visits: 1485, total_reward: 413, action: e3h, visits: 14, total_reward: -12, action: c4v, visits: 14, total_reward: -12, action: h7v, visits: 17, total_reward: -13, action: c3h, visits: 17, total_reward: -13, action: a8v, visits: 20, total_reward: -14, action: e5h, visits: 106, total_reward: -14, action: g1v, visits: 20, total_reward: -14, action: h3v, visits: 22, total_reward: -14]\n",
      "search time: 589.8032073974609\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: b8v, visits: 773, total_reward: 87, action: f5h, visits: 758, total_reward: 84, action: g8h, visits: 711, total_reward: 75, action: h7h, visits: 531, total_reward: 43, action: e5h, visits: 461, total_reward: 39, action: f8h, visits: 185, total_reward: -9, action: e2h, visits: 18, total_reward: -14, action: g2h, visits: 20, total_reward: -14, action: d1v, visits: 23, total_reward: -15, action: c4v, visits: 23, total_reward: -15]\n",
      "search time: 555.5639815330505\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: g8h, visits: 5406, total_reward: 1512, action: d9, visits: 11, total_reward: -11, action: h1v, visits: 11, total_reward: -11, action: g4h, visits: 11, total_reward: -11, action: f1h, visits: 14, total_reward: -12, action: h2h, visits: 14, total_reward: -12, action: h6v, visits: 14, total_reward: -12, action: h4h, visits: 17, total_reward: -13, action: c4v, visits: 17, total_reward: -13, action: a6v, visits: 17, total_reward: -13]\n",
      "search time: 536.2626931667328\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: e8h, visits: 5798, total_reward: 1152, action: e8v, visits: 13, total_reward: -13, action: d1v, visits: 13, total_reward: -13, action: f2h, visits: 17, total_reward: -15, action: f5h, visits: 17, total_reward: -15, action: f7v, visits: 17, total_reward: -15, action: b4v, visits: 20, total_reward: -16, action: d5v, visits: 20, total_reward: -16, action: d2v, visits: 20, total_reward: -16, action: f3h, visits: 23, total_reward: -17]\n",
      "search time: 527.4653911590576\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: c8h, visits: 4302, total_reward: 714, action: d7v, visits: 632, total_reward: 38, action: a4v, visits: 13, total_reward: -13, action: d1h, visits: 16, total_reward: -14, action: b6h, visits: 21, total_reward: -15, action: g6h, visits: 21, total_reward: -15, action: g1h, visits: 21, total_reward: -15, action: d8v, visits: 26, total_reward: -16, action: f3h, visits: 24, total_reward: -16, action: g2v, visits: 24, total_reward: -16]\n",
      "search time: 503.91702675819397\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: g4h, visits: 1568, total_reward: 340, action: a2h, visits: 716, total_reward: 118, action: d5v, visits: 618, total_reward: 94, action: a1v, visits: 497, total_reward: 65, action: a8h, visits: 298, total_reward: 22, action: f2v, visits: 263, total_reward: 15, action: d9, visits: 251, total_reward: 13, action: h7v, visits: 236, total_reward: 10, action: a7h, visits: 215, total_reward: 7, action: b5v, visits: 164, total_reward: -2]\n",
      "search time: 494.5190987586975\n",
      "searching\n",
      "iteration 1\n",
      "iteration 1001\n",
      "iteration 2001\n",
      "iteration 3001\n",
      "iteration 4001\n",
      "iteration 5001\n",
      "iteration 6001\n",
      "iteration 7001\n",
      "iteration 8001\n",
      "iteration 9001\n",
      "[action: h7v, visits: 2015, total_reward: 141, action: c4h, visits: 256, total_reward: 0, action: f4v, visits: 14, total_reward: -14, action: f1h, visits: 17, total_reward: -15, action: d7h, visits: 17, total_reward: -15, action: f5h, visits: 20, total_reward: -16, action: a2v, visits: 20, total_reward: -16, action: h3v, visits: 26, total_reward: -18, action: e4h, visits: 26, total_reward: -18, action: g7h, visits: 26, total_reward: -18]\n",
      "search time: 115.54777097702026\n",
      "You won!\n",
      "e2/a5h/e3/e6v/e4/c2v/e5/d6h/f5/b8v/f6/g8h/f7/e8h/f8/c8h/g8/g4h/h8/h7v/h7/f9/h6/g9/i6/h9/i7/i9/i8/i7/i9\n"
     ]
    }
   ],
   "source": [
    "play(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1621d",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### Computation time\n",
    "\n",
    "From the experiments we can see that there is a linear relationship between the iterations and computation time. \n",
    "\n",
    "### Performance\n",
    "Looking at the moves the MCTS algorithm made at 100 and 1000, we see that the agent is basically useless it was not able to block the player from moving to its goal. The key for the MCTS algorithm is basically to find the best wall moves, since the placements of the walls determine the result in the end. Looking at an iteration of 10000 we can see that the agent starts to recognized that it needs to play a wall to block the player at somepoint, but this is not good enough, also the search time gets really high, so I we want to have a better MCTS agent, its preferrable to not have a higher amount if iterations, \n",
    "### Improvement points\n",
    "\n",
    "\n",
    "#### More efficient code\n",
    "Improvement points for the MCTS algorithm could be trying to reduce the search time in order to still try out a higher number of iterations while keeping the search time acceptable. This could be done by writing more efficient code. Analysis of the code needs te be performed in order to determine how to write it more efficient. \n",
    "\n",
    "#### Heuristic rules\n",
    "Another solution that could improve the MCTS algorithm is by adding heuristic rules to the rollout policy so that the games that are being simulated generate more value for the algorithm.\n",
    "\n",
    "Potential Heuristic rules: \n",
    "\n",
    "- Distance to the goal: Assign a higher value to moves that bring the player closer to their goal position. This heuristic encourages the agent to prioritize moves that help it reach the goal quickly.\n",
    "\n",
    "- Blocking opponents: Consider moves that block the opponent's path to their goal. By placing walls to hinder the opponent's progress, the agent can gain an advantage.\n",
    "\n",
    "- Better Wall placement: Analyze the board configuration and identify critical positions where placing a wall can have a significant impact. \n",
    "\n",
    "- Follow shortest path when players has zero walls: There is no need to perform MCTS if the agent does not have any walls left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e23ac5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The goal of this notebook was to find out the increase of performance when we increase the number of iterations and to see how the search time grows when we increase the iterations.\n",
    "\n",
    "From the results I conclude that there is a linear relationship between search time and iterations and that performance increases when we increase the number of iterations. The performance of MCTS at a high number of iterations. In future experiments by adding heuristic rules I expect better performance of the MCTS algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8c3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
